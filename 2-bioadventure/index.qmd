---
title: Bioassessment Data Adventure
engine: knitr
format: 
  live-html:
      toc: true
webr:
  render-df: gt-interactive
  packages:
    - dplyr
    - tidyr
    - ggplot2
    - janitor
  cell-options:
    min-lines: 3
    editor-font-scale: 0.8
    fig-width: 7
    fig-height: 4.3
    out-width: "100%"
editor_options: 
  chunk_output_type: console
---

{{< include ../_extensions/r-wasm/live/_knitr.qmd >}}


The general approach here can be to join tables (need to update site locations to include the county so as to avoid needing sf and tigris).

Join tables, summarize by county, find county with highest CSCI scores and county with lowest CSCI scores.

Generate a quick box plot comparison by county

Look at trend latitudinally 

Generate summary table of stations to monitor

Find counties with fewest stations and identify sampling gaps

## Import our Data

First off we want to import our data so we can use it. For this data adventure, let's import three pieces, the `CSCI` values, the `ASCI` values, and a corresponding latitude & longitude list of our stations. We can then integrate all these pieces.

::: {.callout-tip}

## ðŸ“£ Load Libraries
If you are following along in your own RStudio Project, make sure to load the libraries first!^[These libraries are loaded automagically behind the scenes in this webpage, which is why we don't load them below.]  
We will use the following in this tutorial:

```
library(dplyr)
library(tidyr)
library(janitor)
library(ggplot2)
```
:::


```{webr}
# Benthic Macroinvertebrate Data
csci_url <- "https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/cscidat.csv"
cscidat <- read.csv(csci_url)
str(cscidat)

# Algae Data
asci_url <- "https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/ascidat.csv"
ascidat <- read.csv(asci_url)
glimpse(ascidat)

# Site Location Data
latlons <- read.csv(file =  "https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/latlon.csv")
glimpse(latlons)

```

## Selecting and Filtering

A big part of working with data is figuring out how to  `select`, `filter`, `slice`,, and `summarize`our data into the pieces we want. The good news is each of these things is a function in the {dplyr} package, so we can walk through a few examples for each of these *verbs*.

### `select`

We `select` columns. There are many options we can use to select the columns we want. Here are a few options, but there are many! Remember, we need to have loaded our `dplyr` package first. 

::: {.callout-tip}
## ðŸ“£ To "Quote" or not to Quote

One difficult thing to be aware of in R is when and where we use quotation marks. For the most part, calling column names in dplyr does **Not* require quoting. However, if we are using specific values, these typically need to be "quoted". Stay tuned for more!

:::

```{webr}
# first, select some columns
sel_1 <- select(
  # first the data
  .data = cscidat,
  # next the columns we want
  SampleID_old, New_Lat, New_Long, CSCI) 

glimpse(sel_1)
```

Try selecting everything but a few columns. Let's select all *but* `CSCI` and `COMID`

```{webr}
sel_2 <- select(cscidat, -CSCI, -COMID)
names(sel_2)

# another way to write this is using "c(CSCI, COMID)"
# however we need to put the "-" in front 
sel_2 <- select(cscidat, -c(CSCI, COMID))
```

Or we can select a columns that start with `"New"`

```{webr}
# select columns that start with "New"
sel_3 <- select(cscidat, starts_with('New'))

# or same sort of thing
sel_3 <- select(cscidat, contains('New'))
head(sel_3)
```

### `filter`

We `filter` **rows**. After we select some columns, youâ€™ll probably want to remove observations that donâ€™t fit some criteria. For example, maybe you want to remove CSCI scores less than some threshold, or find stations above a certain latitude, or both.

```{webr}
# get CSCI scores greater than 0.79
filt_1 <- filter(cscidat, CSCI > 0.79)
summary(filt_1$CSCI) # get summary of single column with `$`

# get CSCI scores above latitude 37N
filt_2 <- filter(cscidat, New_Lat > 37)
summary(filt_2$New_Lat)
```

We can chain these together. In `filter()`, there are many ways to do this, but be aware if we use a `,` to separate different filters, it is treated as **`and`**. So both arguments must be met. For an either / or filter, we'd want to use a vertical bar, `|` separating our arguments.

```{webr}
# get CSCI scores above latitude 37N
filt_3 <- filter(cscidat, New_Lat > 37, CSCI > 0.79)

# check with summary
select(filt_3, New_Lat, CSCI) |> summary()
```

::: {.callout-tip}
## ðŸ§° Chaining or Piping (`%>%` or `|>`)

We can chain code together by using a pipe argument (`%>%` or `|>`). These can be viewed as passing whatever is coming from the left side, on to the right side. Think of this as doing an operation on an object, pass to the pipe (`|>`) **and then** doing another operation. 

So, above, we select columns from our filtered dataset, **and then** we summarize those columns.

:::

### `slice`

`slice` is another function in the `{dplyr}` package, which allows us to do additional filtering of data based on values or summarizing actions. Here we'll use it to find the top ten CSCI values, but it is a powerful function with many uses, and can be easily chained together with other functions like `filter` and `select`.

```{webr}
# get top 10 highest CSCI scores 
csci_top_10 <- slice_max(cscidat, order_by = CSCI, n = 10)

# now get bottom 10 and select only the Station Code and CSCI score
csci_bot_10 <- slice_min(cscidat, order_by=CSCI, n=10) |> 
  select(StationCode, CSCI)
```


## Renaming

Often times we need to rename our columns in order to make joining data easier, or for tables and plots that we want to share out. There are a few ways to rename columns in R.

We can use the `dplyr::rename()` function to specifically rename columns of interest. This requires the data, and a list of the columns we are interested in changing, formatted as: `new_name` = `old_name`.

```{webr}
# rename with dplyr
cscidat_lower <- rename(cscidat, 
              id = SampleID_old, 
              lat = New_Lat, 
              lon = New_Long)
names(cscidat_lower)
```

ðŸ§° Another great tool is the `{janitor}` package. We can use a number of functions in janitor, but most commonly I use it to clean all the column names. 

```{webr}
# rename all columns with janitor
cscidat_janitor <- janitor::clean_names(cscidat)
names(cscidat_janitor)

# take a look at options in the clean_names() function
# how can we change the case to inital caps?
# hint: help("clean_names")
```


## Modifying and Summarizing Data

When we want to add, revise, or summarize our data, we need to use a few additional functions in `{dplyr}`. We can use these to create new columns, calculate new data based on existing data, or create summaries based on different groups within our data.

### `mutate` (adding columns)

Weâ€™ve seen how to `filter` observations (rows) and `select` columns of a data frame. In `{dplyr}`, `mutate` allows us to add new columns to an existing data frame. These can be vectors you are adding or based on expressions applied to existing columns. For instance, maybe we want to convert a numeric column into a categorical using some criteria or maybe we want to make a new column based on some arithmetic on some other columns.

```{webr}
# get observed taxa
mut_1 <- mutate(cscidat, observed = OE * E)
glimpse(mut_1)

# add a column for lo/hi csci scores
mut_2 <- mutate(mut_1, CSCIcat = ifelse(CSCI <= 0.79, 'lo', 'hi'))
glimpse(mut_2)
```

### `summarize` Data

A very powerful verb in the `{dplyr}` package is `summarize`. Note, when we use `mutate`, we get back the same data frame, but with whatever revision or addition we have made to the columns. With `summarize`, we will get a **new dataframe** based on the summary operation we have requested.

The key with `summarize` is there is typically some sort of grouping variable that we want to use to do our summary. For example, maybe we want to get the max and min CSCI score by the stream `COMID` (unique segment ID for every stream line). 

```{webr}
csci_maxmin_by_comid <- cscidat |> # using pipe here to pass data on
  # pick the variable to group/summarize by
  group_by(COMID) |> 
  summarize(maxCSCI = max(CSCI, na.rm=TRUE),
            minCSCI = min(CSCI, na.rm=TRUE))
glimpse(csci_maxmin_by_comid)
```

What if we want to know which of these `COMIDs` actually had more than one value to calculate the `min` and `max`? We can use another summarizing shortcut called `tally`. It works the same way as `summarize` but is designed specifically for counting unique values, or getting the sum of those values based on a grouping value.

We can combine this with `arrange` to sort our data by a column of interest, and `desc` to sort in descending order.

```{webr}
comid_tally <- cscidat |> 
  group_by(COMID) |> 
  tally() |>  # sum how many unique COMID
  filter(n>1) |> # tally generates a column "n" we can use
  arrange(desc(n)) # sort "n" from largest to smallest
head(comid_tally)
```

### `bind` Data

Sometimes when we don't need to worry about joining specifically, and we want to append or mash datasets together, we can use the **bind** functions. There are base options as well as `{dplyr}` options. Let's revisit the `slice` function we used above, and make a new dataframe that is just the *StationCode*, *CSCI*, and *Lat* and *Lon* for the top 10 and bottom 10 CSCI values. We can bind rows, or bind columns, depending on what we are trying to do.

```{webr}
# get top 10 highest CSCI scores 
csci_top_10 <- slice_max(cscidat, order_by = CSCI, n = 10) |>   select(StationCode, CSCI, New_Lat, New_Long)

# now get bottom 10
csci_bot_10 <- slice_min(cscidat, order_by=CSCI, n=10) |> 
    select(StationCode, CSCI, New_Lat, New_Long)

# now BIND!
csci_top_bottom <- bind_rows(csci_top_10, csci_bot_10)
csci_top_bottom

# if we had different columns in each 
# data frame, what would happen with our bind?
```

::: {.callout-tip}

## ðŸ“£ Binding data frames
Remember, a vector is essentially a *column* of a single type of data. And data frames have to have columns with the same number of rows. So when binding rows, they need to be the same data `class` in each column, and when binding columns, they must have the same number of rows as the data frame. 

:::


## Joining

Combining data is a common task of data wrangling. All joins require that each of the tables can be linked by some shared identifier or **_key_** columns. These are usually represented as columns that are unique for each observations. Our example datasets include the `StationID` or `SampleID` columns that represent unique identifiers of the station, sample date, and/or replicate.

The challenge with joins is that the two datasets may not represent the same observations for a given key. For example, you might have one table with all observations for every key, another with only some observations, or two tables with only a few shared keys. What you get back from a join will depend on whatâ€™s shared between tables, in addition to the type of join you use.

For our data, weâ€™ll be using an **`inner_join`** that combines datasets by shared keys ( {{<  fa arrows-turn-right >}} *for an overview of the other types of joins, see* [R4DS lesson here](https://r4ds.had.co.nz/relational-data.html#mutating-joins)).

![Figures by Garrick Adenbuie, see [here for more](https://www.garrickadenbuie.com/project/tidyexplain/)](https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/inner-join.gif)

We need to either rename the **key** columns of interest so they are identical, or we can specify them explicitly when joining. Let's show both options below:

```{webr}
## OPTION 1: CHANGE COLUMNS TO THE SAME "KEY" NAME
# rename to "id" so cscidat matches ascidat
csci_renamed <- rename(cscidat, id = SampleID_old)

# join
all_data <- inner_join(csci_renamed, ascidat, by = 'id')
glimpse(all_data) # note how many rows and columns
# we expect to have added any matching rows from ascidat

## OPTION 2: SPECIFY THE KEY COLUMNS FOR EACH IN JOIN
all_data <- inner_join(cscidat, ascidat, by=c("SampleID_old"="id"))
glimpse(all_data)

# try summary of all_data
```

Let's look at these two approaches above, break down the differences, and talk about what happened. Joins are particularly important, but can be difficult to deal with.

We could join by multiple columns, so if we wanted to join by `id` and the `New_Lat` and `New_Long` fields, we could say `by=c("SampleID_old"="id", "New_Lat", "New_Long")`. 
Note, for columns with the exact same name, we don't need the `=` to define for each dataset. 

It is always important to bear in mind what type of join we are using, understand and inspect the results, and check that against expectations of what we think we should get back. The computer will only do what we tell it, for better or worse!

## Plotting with [`ggplot2`](https://ggplot2.tidyverse.org/)

The entire workflow of data exploration often hinges on looking at your data, whether youâ€™re exploring a dataset for the first time or creating publication-ready figures. Visualizing your data is important to provide insight into patterns, and opens the door to asking different questions.

R is an amazing system for visualizing data, and we can only scratch the surface! We will introduce some of the core concepts and structure of the popular {`ggplot2`} package. Based on what is known as the **g**rammar of **g**raphics, designed to make thinking, reasoning, and communicating about graphs easier by following a few simple rules. Like learning to write a sentence, the grammar of building a graph also must start with a standardized foundation that can be used for building more complex visualizations.

### `ggplot()`

The nice thing is that with {`ggplot2`}, everything begins with the function `ggplot()`. Then we can add layers to this foundation. The first argument of `ggplot()` is the dataset to use in the graph. So this creates an empty plot:

```{webr}

ggplot(data = all_data)

```

### [`geoms`](https://ggplot2.tidyverse.org/reference/index.html#geoms)

Once we have added the foundation, we then can build the figure we want, layer by layer. These are typically `geoms` or geometries that correspond with a type of visualization. For example, the function `geom_point()` adds a layer of points to your plot, which creates a scatterplot. {`ggplot2`} comes with **_many_** [`geom`](https://ggplot2.tidyverse.org/reference/index.html#geoms) functions that each add a different type of layer to a plot. 

**ðŸ“£ One important difference to be aware of, layers in `ggplot` are added using a `+`, not a pipe!**

### `geom` arguments

Every `geom_` function in {`ggplot2`} takes these important components.

 - **data**: This can be specified in the foundation `ggplot()` call, or in individual `geom_` layers. By default, `{ggplot2}` looks for the mapped variable in the `ggplot(data=)` argument, which in our case, comes from `all_data`.
 - **mapping** arguments. These define the aesthetics of the layer, and specify how variables in your dataset are mapped to visual properties. 
    - `aes()`: The aesthetic function, which is where we typically always specify the `x=` and `y=` arguments to map variables to the x and y axes. 

Here's the core unit of every `ggplot`:

```
ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))
```

And here's what it actually looks like in practice:

```{webr}
# build the foundation
ggplot(data = all_data) +
    # add a geometry
    geom_point( aes(x=CSCI, y=ASCI) )
```

::: {.callout-tip}

## ðŸ“£ Specifying Argument Names
You may notice sometimes we drop the function argument names (`geom_point(aes())` instead of `geom_point(mapping=aes())`). Functions will usually work without the argument name, assuming we put the values in the same order that the function expects. *However*, in some cases it is important to be specific. Specifying the `data=` argument is often important in `ggplot`. You'll get a sense of when and where we can drop those argument names as you play with plotting!
:::

### A `geom_boxplot`

Let's make one final plot to practice, and get a sense of the data. Let's make a boxplot by the different stream types. You'll notice an `NA` category. How can we `filter` out the `NA`s from the data and remake the plot?

:::: {.panel-tabset}

## Challenge

```{webr}
#| setup: true
#| exercise: ex_1
library(ggplot2)
```

```{webr}
#| exercise: ex_1
ggplot(data = all_data |> _____ ) +
  geom_boxplot(mapping = aes(x = site_type, y = CSCI)) 
```

## Hints

::: { .hint exercise="ex_1"}
Consider piping the `filter()` function from `dplyr`. 
We can then try the negate (`!`) with `is.na()` for `CSCI` and `site_type`.

```r
|> filter(!is.na( _____ )) +
```
:::

## Solution

::: { .solution exercise="ex_1" }
Use the `filter()` function from `dplyr`:

```r
ggplot(data = all_data |> #<1>
filter(!is.na(site_type), !is.na(CSCI))) + #<2>
  geom_boxplot(mapping = aes(x = site_type, y = CSCI)) #<3>

```
1. Take `all_data` while in `ggplot()`, and then,
2. Filter out NA from `site_type` and `CSCI` and make sure to close the `ggplot()`
3. Add the `geom_boxplot()`
:::

::::
