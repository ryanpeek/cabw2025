{
  "hash": "2699b886cf1e4ab3db5f37334029ec8f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Data Wrangling\nengine: knitr\nformat: live-html\ntoc: true\nwebr:\n  render-df: gt-interactive\n  packages:\n    - dplyr\n    - ggplot2\n  cell-options:\n    editor-font-scale: 0.8\n    fig-width: 7\n    fig-height: 4.3\n    out-width: \"100%\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n# Getting Started with Data\n\nThere are many ways to learn/teach R, but one of the best ways is to jump right in with some data you can get your hands dirty with. R is an amazing tool, and often there are many ways to do the same thing, however we need to start with data!\n\n## Data Background \n\nThe data set we are going to play with are part of the California Stream Condition Index (CSCI) and the Algal Stream Condition Index (ASCI). These data represent a portion of the sampling sites that were used to develop each index. The CSCI is based on the comparison of the observed assemblage of benthic macroinvertebrate species to those expected from studying reference streams. It provides a scientifically robust way of assessing and describing conditions and tracking conditions over time or in response to regulatory or restoration actions. \n\nThe Index has two components: \n\n - Ratio of observed to expected taxanomic groups \n - Proportion of the assemblage that falls into different functional groups that represent species diversity, ecosystem function, and sensitivity to stress.\n \nThe Index is not normalized to a 0 to 1 or 100 scale, but instead compares Index values at test sites to values at comparable reference sites. The mean Index value of reference sites is 1.01. The 90th percentile value is 0.85, thus:\n\n - streams with values >0.85 are considered to be [**likely intact**]{.green}\n - streams with values between 0.72 and 0.85 are considered [**likely altered**]{.orange}\n - streams with values <0.72 are considered [**very likely altered**]{.reddark2}\n\nFor more information about these data, and lots of great research showing the utility for monitoring, watershed health, and more, check out [here](https://ftp.sccwrp.org/pub/download/DOCUMENTS/TechnicalReports/883_CSCI-StatewideBioScoringTool.pdf), [here](https://www.waterboards.ca.gov/water_issues/programs/swamp/bioassessment/docs/csci_tech_memo.pdf), [here](https://www.journals.uchicago.edu/doi/10.1086/684130) and [here](https://www.sciencedirect.com/science/article/pii/S1470160X20303587?via%3Dihub).\n\n## Import (Read In) Data\n\nLet's get some data to play with! To start, we'll use a URL of the data set we want to work with, and read it directly from the interwebs into R. It is a `.csv`, which means we can use a `read.csv` function.\n\n\n\n\n::: {.cell}\n```{webr}\n\n# give the full URL to our data (a csv file)\ncsci_url <- \"https://raw.githubusercontent.com/SCCWRP/CABW2018_R_training/master/data/cscidat.csv\"\n\n# read in this data and assign it to the name `cscidat`\ncscidat <- read.csv(csci_url)\n\n# take a quick look at the data\nstr(cscidat)\n\n```\n:::\n\n::: {.cell}\n```{webr}\n\nstarwars |>\n  filter(height < 100) |>\n  select(name, height, mass)\n\n```\n:::\n\n::: {.cell}\n```{webr}\n\n\nlatlons <- read.csv(file =  \"https://raw.githubusercontent.com/SCCWRP/CABW2018_R_training/master/data/latlon.csv\")\n\nglimpse(latlons)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}