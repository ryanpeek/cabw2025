{
  "hash": "972be6f693e0edb50c00eb157d79ea99",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bioassessment Data Adventure\nengine: knitr\nformat: \n  live-html:\n      toc: true\nwebr:\n  render-df: gt-interactive\n  packages:\n    - dplyr\n    - tidyr\n    - ggplot2\n    - janitor\n  cell-options:\n    min-lines: 3\n    editor-font-scale: 0.8\n    fig-width: 7\n    fig-height: 4.3\n    out-width: \"100%\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n## Import our Data\n\nFirst off we want to import our data so we can use it. For this data adventure, let's import three pieces, the `CSCI` values, the `ASCI` values, and a corresponding latitude & longitude list of our stations. We can then integrate all these pieces.\n\n::: {.callout-tip}\n\n## ðŸ“£ Load Libraries\nIf you are following along in your own RStudio Project, make sure to load the libraries first!^[These libraries are loaded automagically behind the scenes in this webpage, which is why we don't load them below.]  \nWe will use the following in this tutorial:\n\n```\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(janitor)\nlibrary(ggplot2)\n```\n:::\n\n\n\n::: {.cell}\n```{webr}\n# Benthic Macroinvertebrate Data\ncsci_url <- \"https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/cscidat.csv\"\ncscidat <- read.csv(csci_url)\nstr(cscidat)\n\n# Algae Data\nasci_url <- \"https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/ascidat.csv\"\nascidat <- read.csv(asci_url)\nglimpse(ascidat)\n\n# Site Location Data\nlatlons <- read.csv(file =  \"https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/latlon.csv\")\nglimpse(latlons)\n\n```\n:::\n\n\n## Selecting and Filtering\n\nA big part of working with data is figuring out how to  `select`, `filter`, `slice`,, and `summarize` our data into the pieces we want. The good news is each of these things is a function in the {`dplyr`} package, so we can walk through a few examples for each of these *verbs*.\n\n### `select`\n\nWe `select` columns. There are many options we can use to select the columns we want. Here are a few options, but there are many! Remember, we need to have loaded our `dplyr` package first. \n\n::: {.callout-tip}\n## ðŸ“£ To \"Quote\" or not to Quote\n\nOne difficult thing to be aware of in R is when and where we use quotation marks. For the most part, calling column names in `dplyr` does **Not** require quoting. However, if we are using specific values, these typically need to be \"quoted\". Stay tuned for more!\n\n:::\n\n\n::: {.cell}\n```{webr}\n# first, select some columns\nsel_1 <- select(\n  # first the data\n  .data = cscidat,\n  # next the columns we want\n  SampleID_old, New_Lat, New_Long, CSCI) \n\nglimpse(sel_1)\n```\n:::\n\n\nTry selecting everything but a few columns. Let's select all *but* `CSCI` and `COMID`\n\n\n::: {.cell}\n```{webr}\nsel_2 <- select(cscidat, -CSCI, -COMID)\nnames(sel_2)\n\n# another way to write this is using \"c(CSCI, COMID)\"\n# however we need to put the \"-\" in front \nsel_2 <- select(cscidat, -c(CSCI, COMID))\n```\n:::\n\n\nOr we can select a columns that start with `\"New\"`\n\n\n::: {.cell}\n```{webr}\n# select columns that start with \"New\"\nsel_3 <- select(cscidat, starts_with('New'))\n\n# or same sort of thing\nsel_3 <- select(cscidat, contains('New'))\nhead(sel_3)\n```\n:::\n\n\n### `filter`\n\nWe `filter` **rows**. After we select some columns, youâ€™ll probably want to remove observations that donâ€™t fit some criteria. For example, maybe you want to remove CSCI scores less than some threshold, or find stations above a certain latitude, or both.\n\n\n::: {.cell}\n```{webr}\n# get CSCI scores greater than 0.79\nfilt_1 <- filter(cscidat, CSCI > 0.79)\nsummary(filt_1$CSCI) # get summary of single column with `$`\n\n# get CSCI scores above latitude 37N\nfilt_2 <- filter(cscidat, New_Lat > 37)\nsummary(filt_2$New_Lat)\n```\n:::\n\n\nWe can chain these together. In `filter()`, there are many ways to do this, but be aware if we use a `,` to separate different filters, it is treated as **`and`**. So both arguments must be met. For an either / or filter, we'd want to use a vertical bar, `|` separating our arguments.\n\n\n::: {.cell}\n```{webr}\n# get CSCI scores above latitude 37N\nfilt_3 <- filter(cscidat, New_Lat > 37, CSCI > 0.79)\n\n# check with summary\nselect(filt_3, New_Lat, CSCI) |> summary()\n```\n:::\n\n\n::: {.callout-tip}\n## ðŸ§° Chaining or Piping (`%>%` or `|>`)\n\nWe can chain code together by using a pipe argument (`%>%` or `|>`). These can be viewed as passing whatever is coming from the left side, on to the right side. Think of this as doing an operation on an object, pass to the pipe (`|>`) **and then** doing another operation. \n\nSo, above, we select columns from our filtered dataset, **and then** we summarize those columns.\n\n:::\n\n### `slice`\n\n`slice` is another function in the `{dplyr}` package, which allows us to do additional filtering of data based on values or summarizing actions. Here we'll use it to find the top ten CSCI values, but it is a powerful function with many uses, and can be easily chained together with other functions like `filter` and `select`.\n\n\n::: {.cell}\n```{webr}\n# get top 10 highest CSCI scores \ncsci_top_10 <- slice_max(cscidat, order_by = CSCI, n = 10)\n\n# now get bottom 10 and select only the Station Code and CSCI score\ncsci_bot_10 <- slice_min(cscidat, order_by=CSCI, n=10) |> \n  select(StationCode, CSCI)\n```\n:::\n\n\n\n## Renaming\n\nOften times we need to rename our columns in order to make joining data easier, or for tables and plots that we want to share out. There are a few ways to rename columns in R.\n\nWe can use the `dplyr::rename()` function to specifically rename columns of interest. This requires the data, and a list of the columns we are interested in changing, formatted as: `new_name` = `old_name`.\n\n\n::: {.cell}\n```{webr}\n# rename with dplyr\ncscidat_lower <- rename(cscidat, \n              id = SampleID_old, \n              lat = New_Lat, \n              lon = New_Long)\nnames(cscidat_lower)\n```\n:::\n\n\nðŸ§° Another great tool is the `{janitor}` package. We can use a number of functions in janitor, but most commonly I use it to clean all the column names. \n\n\n::: {.cell}\n```{webr}\n# rename all columns with janitor\ncscidat_janitor <- janitor::clean_names(cscidat)\nnames(cscidat_janitor)\n\n# take a look at options in the clean_names() function\n# how can we change the case to inital caps?\n# hint: help(\"clean_names\")\n```\n:::\n\n\n\n## Modifying and Summarizing Data\n\nWhen we want to add, revise, or summarize our data, we need to use a few additional functions in `{dplyr}`. We can use these to create new columns, calculate new data based on existing data, or create summaries based on different groups within our data.\n\n### `mutate` (adding columns)\n\nWeâ€™ve seen how to `filter` observations (rows) and `select` columns of a data frame. In `{dplyr}`, `mutate` allows us to add new columns to an existing data frame. These can be vectors you are adding or based on expressions applied to existing columns. For instance, maybe we want to convert a numeric column into a categorical using some criteria or maybe we want to make a new column based on some arithmetic on some other columns.\n\n\n::: {.cell}\n```{webr}\n# get observed taxa\nmut_1 <- mutate(cscidat, observed = OE * E)\nglimpse(mut_1)\n\n# add a column for lo/hi csci scores\nmut_2 <- mutate(mut_1, CSCIcat = ifelse(CSCI <= 0.79, 'lo', 'hi'))\nglimpse(mut_2)\n```\n:::\n\n\n### `summarize` Data\n\nA very powerful verb in the `{dplyr}` package is `summarize`. Note, when we use `mutate`, we get back the same data frame, but with whatever revision or addition we have made to the columns. With `summarize`, we will get a **new dataframe** based on the summary operation we have requested.\n\nThe key with `summarize` is there is typically some sort of grouping variable that we want to use to do our summary. For example, maybe we want to get the max and min CSCI score by the stream `COMID` (unique segment ID for every stream line). \n\n\n::: {.cell}\n```{webr}\ncsci_maxmin_by_comid <- cscidat |> # using pipe here to pass data on\n  # pick the variable to group/summarize by\n  group_by(COMID) |> \n  summarize(maxCSCI = max(CSCI, na.rm=TRUE),\n            minCSCI = min(CSCI, na.rm=TRUE))\nglimpse(csci_maxmin_by_comid)\n```\n:::\n\n\nWhat if we want to know which of these `COMIDs` actually had more than one value to calculate the `min` and `max`? We can use another summarizing shortcut called `tally`. It works the same way as `summarize` but is designed specifically for counting unique values, or getting the sum of those values based on a grouping value.\n\nWe can combine this with `arrange` to sort our data by a column of interest, and `desc` to sort in descending order.\n\n\n::: {.cell}\n```{webr}\ncomid_tally <- cscidat |> \n  group_by(COMID) |> \n  tally() |>  # sum how many unique COMID\n  filter(n>1) |> # tally generates a column \"n\" we can use\n  arrange(desc(n)) # sort \"n\" from largest to smallest\nhead(comid_tally)\n```\n:::\n\n\n### `bind` Data\n\nSometimes when we don't need to worry about joining specifically, and we want to append or mash datasets together, we can use the **bind** functions. There are base options as well as `{dplyr}` options. Let's revisit the `slice` function we used above, and make a new dataframe that is just the *StationCode*, *CSCI*, and *Lat* and *Lon* for the top 10 and bottom 10 CSCI values. We can bind rows, or bind columns, depending on what we are trying to do.\n\n\n::: {.cell}\n```{webr}\n# get top 10 highest CSCI scores \ncsci_top_10 <- slice_max(cscidat, order_by = CSCI, n = 10) |>   select(StationCode, CSCI, New_Lat, New_Long)\n\n# now get bottom 10\ncsci_bot_10 <- slice_min(cscidat, order_by=CSCI, n=10) |> \n    select(StationCode, CSCI, New_Lat, New_Long)\n\n# now BIND!\ncsci_top_bottom <- bind_rows(csci_top_10, csci_bot_10)\ncsci_top_bottom\n\n# if we had different columns in each \n# data frame, what would happen with our bind?\n```\n:::\n\n\n::: {.callout-tip}\n\n## ðŸ“£ Binding data frames\nRemember, a vector is essentially a *column* of a single type of data. And data frames have to have columns with the same number of rows. So when binding rows, they need to be the same data `class` in each column, and when binding columns, they must have the same number of rows as the data frame. \n\n:::\n\n\n## Joining\n\nCombining data is a common task of data wrangling. All joins require that each of the tables can be linked by some shared identifier or **_key_** columns. These are usually represented as columns that are unique for each observations. Our example datasets include the `StationID` or `SampleID` columns that represent unique identifiers of the station, sample date, and/or replicate.\n\nThe challenge with joins is that the two datasets may not represent the same observations for a given key. For example, you might have one table with all observations for every key, another with only some observations, or two tables with only a few shared keys. What you get back from a join will depend on whatâ€™s shared between tables, in addition to the type of join you use.\n\nFor our data, weâ€™ll be using an **`inner_join`** that combines datasets by shared keys ( {{<  fa arrows-turn-right >}} <span style=\"color:orange;\">for an overview of the other types of joins, see [R4DS lesson here](https://r4ds.had.co.nz/relational-data.html#mutating-joins) </span>).\n\n![Figures by Garrick Adenbuie, see [here for more](https://www.garrickadenbuie.com/project/tidyexplain/)](https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/inner-join.gif)\n\nWe need to either rename the **key** columns of interest so they are identical, or we can specify them explicitly when joining. Let's show both options below:\n\n\n::: {.cell}\n```{webr}\n## OPTION 1: CHANGE COLUMNS TO THE SAME \"KEY\" NAME\n# rename to \"id\" so cscidat matches ascidat\ncsci_renamed <- rename(cscidat, id = SampleID_old)\n\n# join\nall_data <- inner_join(csci_renamed, ascidat, by = 'id')\nglimpse(all_data) # note how many rows and columns\n# we expect to have added any matching rows from ascidat\n\n## OPTION 2: SPECIFY THE KEY COLUMNS FOR EACH IN JOIN\nall_data <- inner_join(cscidat, ascidat, by=c(\"SampleID_old\"=\"id\"))\nglimpse(all_data)\n\n# try summary of all_data\n```\n:::\n\n\nLet's look at these two approaches above, break down the differences, and talk about what happened. Joins are particularly important, but can be difficult to deal with.\n\nWe could join by multiple columns, so if we wanted to join by `id` and the `New_Lat` and `New_Long` fields, we could say `by=c(\"SampleID_old\"=\"id\", \"New_Lat\", \"New_Long\")`. \nNote, for columns with the exact same name, we don't need the `=` to define for each dataset. \n\nIt is always important to bear in mind what type of join we are using, understand and inspect the results, and check that against expectations of what we think we should get back. The computer will only do what we tell it, for better or worse!\n\n## Plotting with [{`ggplot2`}](https://ggplot2.tidyverse.org/)\n\nThe entire workflow of data exploration often hinges on looking at your data, whether youâ€™re exploring a dataset for the first time or creating publication-ready figures. Visualizing your data is important to provide insight into patterns, and opens the door to asking different questions.\n\nR is an amazing system for visualizing data, and we can only scratch the surface! We will introduce some of the core concepts and structure of the popular {`ggplot2`} package. Based on what is known as the **g**rammar of **g**raphics, designed to make thinking, reasoning, and communicating about graphs easier by following a few simple rules. Like learning to write a sentence, the grammar of building a graph also must start with a standardized foundation that can be used for building more complex visualizations.\n\n### `ggplot()`\n\nThe nice thing is that with {`ggplot2`}, everything begins with the function `ggplot()`. Then we can add layers to this foundation. The first argument of `ggplot()` is the dataset to use in the graph. So this creates an empty plot:\n\n\n::: {.cell}\n```{webr}\n\nggplot(data = all_data)\n\n```\n:::\n\n\n### [`geoms`](https://ggplot2.tidyverse.org/reference/index.html#geoms)\n\nOnce we have added the foundation, we then can build the figure we want, layer by layer. These are typically `geoms` or geometries that correspond with a type of visualization. For example, the function `geom_point()` adds a layer of points to your plot, which creates a scatterplot. {`ggplot2`} comes with **_many_** [`geom`](https://ggplot2.tidyverse.org/reference/index.html#geoms) functions that each add a different type of layer to a plot. \n\n**ðŸ“£ One important difference to be aware of, layers in `ggplot` are added using a `+`, not a pipe!**\n\n### `geom` arguments\n\nEvery `geom_` function in {`ggplot2`} takes these important components.\n\n - **data**: This can be specified in the foundation `ggplot()` call, or in individual `geom_` layers. By default, `{ggplot2}` looks for the mapped variable in the `ggplot(data=)` argument, which in our case, comes from `all_data`.\n - **mapping** arguments. These define the aesthetics of the layer, and specify how variables in your dataset are mapped to visual properties. \n    - `aes()`: The aesthetic function, which is where we typically always specify the `x=` and `y=` arguments to map variables to the x and y axes. \n\nHere's the core unit of every `ggplot`:\n\n```\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\n```\n\nAnd here's what it actually looks like in practice:\n\n\n::: {.cell}\n```{webr}\n# build the foundation\nggplot(data = all_data) +\n    # add a geometry\n    geom_point( aes(x=CSCI, y=ASCI) )\n```\n:::\n\n\n::: {.callout-tip}\n\n## ðŸ“£ Specifying Argument Names\nYou may notice sometimes we drop the function argument names (`geom_point(aes())` instead of `geom_point(mapping=aes())`). Functions will usually work without the argument name, assuming we put the values in the same order that the function expects. *However*, in some cases it is important to be specific. Specifying the `data=` argument is often important in `ggplot`. You'll get a sense of when and where we can drop those argument names as you play with plotting!\n:::\n\n### A `geom_boxplot`\n\nLet's make one final plot to practice, and get a sense of the data. Let's make a boxplot by the different stream types. You'll notice an `NA` category. How can we `filter` out the `NA`s from the data and remake the plot?\n\n:::: {.panel-tabset}\n\n## Challenge\n\n\n::: {.cell setup='true' exercise='ex_1'}\n```{webr}\n#| setup: true\n#| exercise: ex_1\nlibrary(ggplot2)\n```\n:::\n\n\n\n::: {.cell exercise='ex_1'}\n```{webr}\n#| exercise: ex_1\nggplot(data = all_data |> _____ ) +\n  geom_boxplot(mapping = aes(x = site_type, y = CSCI)) \n```\n:::\n\n\n## Hints\n\n::: { .hint exercise=\"ex_1\"}\nConsider piping the `filter()` function from `dplyr`. \nWe can then try the negate (`!`) with `is.na()` for `CSCI` and `site_type`.\n\n```r\n|> filter(!is.na( _____ )) +\n```\n:::\n\n## Solution\n\n::: { .solution exercise=\"ex_1\" }\nUse the `filter()` function from `dplyr`:\n\n```r\nggplot(data = all_data |> #<1>\nfilter(!is.na(site_type), !is.na(CSCI))) + #<2>\n  geom_boxplot(mapping = aes(x = site_type, y = CSCI)) #<3>\n\n```\n1. Take `all_data` while in `ggplot()`, and then,\n2. Filter out NA from `site_type` and `CSCI` and make sure to close the `ggplot()`\n3. Add the `geom_boxplot()`\n:::\n\n::::\n\n\n## Wrapping Up\n\nSo much can be done using a set of standardized tools. Learning to wield these tools across most any dataset takes time, but each time gets easier. \n\n::: {.callout-tip}\n## ðŸ“£ Things to keep in mind:\n\n - Always keep in mind how data fits together, and what columns can be used to join data\n - Don't be afraid to make summary tables, and visualize. your data early and often!\n - Quick comparisons can be a great way to QA/QC data, and make sure data meets expectations.\n\n:::\n\n### Challenge Questions\n\nTry some of these questions on your own:\n\n1. If you wanted to make a map of the 10 stations with the top 10 CSCI and ASCI scores, you would need a table of the `StationID`, `Lat`, `Lon`, and scores for `CSCI` and `ASCI`. How could you go about this?\n\n2. If you wanted a boxplot of the average ASCI score by county, but including the `site_type` in the boxplot, how would you do it?\n\n3. If you wanted to assess if there were any latitudinal trends in `ASCI` or `CSCI`, what sort of plot could you make? \n\n4. Can you identify which counties have the fewest stations to help identify sampling gaps?\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}