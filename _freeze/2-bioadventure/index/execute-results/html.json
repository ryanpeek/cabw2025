{
  "hash": "9a16158aafc01b733109bb537aa62c11",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bioassessment Data Adventure\nengine: knitr\nformat: \n  live-html:\n      toc: true\nwebr:\n  render-df: gt-interactive\n  packages:\n    - dplyr\n    - tidyr\n    - ggplot2\n    - janitor\n  cell-options:\n    min-lines: 6\n    editor-font-scale: 0.8\n    fig-width: 7\n    fig-height: 4.3\n    out-width: \"100%\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\nThe general approach here can be to join tables (need to update site locations to include the county so as to avoid needing sf and tigris).\n\nJoin tables, summarize by county, find county with highest CSCI scores and county with lowest CSCI scores.\n\nGenerate a quick box plot comparison by county\n\nLook at trend latitudinally \n\nGenerate summary table of stations to monitor\n\nFind counties with fewest stations and identify sampling gaps\n\n## Import our Data\n\nFirst off we want to import our data so we can use it. For this data adventure, let's import three pieces, the `CSCI` values, the `ASCI` values, and a corresponding latitude & longitude list of our stations. We can then integrate all these pieces.\n\n\n\n\n::: {.cell}\n```{webr}\n\ncsci_url <- \"https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/cscidat.csv\"\ncscidat <- read.csv(csci_url)\nstr(cscidat)\n\nasci_url <- \"https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/ascidat.csv\"\nascidat <- read.csv(csci_url)\n\nlatlons <- read.csv(file =  \"https://raw.githubusercontent.com/ryanpeek/cabw2025/refs/heads/main/data/latlon.csv\")\n\nglimpse(latlons)\n\n```\n:::\n\n\n\n\n## Selecting and Filtering\n\nA big part of working with data is figuring out how to  `select`, `filter`, `slice`,, and `summarize`our data into the pieces we want. The good news is each of these things is a function in the {dplyr} package, so we can walk through a few examples for each of these *verbs*.\n\n### `select`\n\nWe `select` columns. There are many options we can use to select the columns we want. Here are a few options, but there are many! Remember, we need to have loaded our `dplyr` package first. \n\n::: {.callout-tip}\n## ðŸ“£ To \"Quote\" or not to Quote\n\nOne difficult thing to be aware of in R is when and where we use quotation marks. For the most part, calling column names in dplyr does **Not* require quoting. However, if we are using specific values, these typically need to be \"quoted\". Stay tuned for more!\n\n:::\n\n\n\n\n::: {.cell}\n```{webr}\n# first, select some columns\nsel_1 <- select(\n  # first the data\n  .data = cscidat,\n  # next the columns we want\n  SampleID_old, New_Lat, New_Long, CSCI) \n\nglimpse(sel_1)\n```\n:::\n\n\n\n\nTry selecting everything but a few columns. Let's select all *but* `CSCI` and `COMID`\n\n\n\n\n::: {.cell}\n```{webr}\n\nsel_2 <- select(cscidat, -CSCI, -COMID)\nnames(sel_2)\n\n# another way to write this is using \"c(CSCI, COMID)\"\n# however we need to put the \"-\" in front \nsel_2 <- select(cscidat, -c(CSCI, COMID))\n\n```\n:::\n\n\n\n\nOr we can select a columns that start with `\"New\"`\n\n\n\n\n::: {.cell}\n```{webr}\n# select columns that start with \"New\"\nsel_3 <- select(cscidat, starts_with('New'))\n\n# or same sort of thing\nsel_3 <- select(cscidat, contains('New'))\nhead(sel_3)\n\n```\n:::\n\n\n\n\n### `filter`\n\nWe `filter` **rows**. After we select some columns, youâ€™ll probably want to remove observations that donâ€™t fit some criteria. For example, maybe you want to remove CSCI scores less than some threshold, or find stations above a certain latitude, or both.\n\n\n\n\n::: {.cell}\n```{webr}\n\n# get CSCI scores greater than 0.79\nfilt_1 <- filter(cscidat, CSCI > 0.79)\n\nsummary(filt_1$CSCI)\n\n# get CSCI scores above latitude 37N\nfilt_2 <- filter(cscidat, New_Lat > 37)\nsummary(filt_2$New_Lat)\n\n```\n:::\n\n\n\n\nWe can chain these together. In `filter()`, there are many ways to do this, but be aware if we use a `,` to separate different filters, it is treated as **`and`**. So both arguments must be met. For an either / or filter, we'd want to use a vertical bar, `|` separating our arguments.\n\n\n\n\n::: {.cell}\n```{webr}\n\n# get CSCI scores above latitude 37N\nfilt_3 <- filter(cscidat, New_Lat > 37, CSCI > 0.79)\n\nselect(filt_3, New_Lat, CSCI) |> summary()\n\n```\n:::\n\n\n\n\n::: {.callout-tip}\n## ðŸ“£ Chaining or Piping (`%>%` or `|>`)\n\nWe can chain code together by using a pipe argument (`%>%` or `|>`). These can be viewed as passing whatever is coming from the left side, on to the right side. Think of this as doing an operation on an object, pass to the pipe (`|>`) **and then** doing another operation. \n\nSo, above, we select columns from our filtered dataset, **and then** we summarize those columns.\n\n:::\n\n### `slice`\n\n`slice` is another function in the `{dplyr}` package, which allows us to do additional filtering of data based on values or summarizing actions. Here we'll use it to find the top ten CSCI values, but it is a powerful function with many uses, and can be easily chained together with other functions like `filter` and `select`.\n\n\n\n\n::: {.cell}\n```{webr}\n\n# get top 10 highest CSCI scores \ncsci_top_10 <- slice_max(cscidat, order_by = CSCI, n = 10)\n\n# now get bottom 10 and select only the Station Code and CSCI score\ncsci_bot_10 <- slice_min(cscidat, order_by=CSCI, n=10) |> \n  select(StationCode, CSCI)\n\n```\n:::\n\n\n\n\n::: {.callout-tip}\n\n## ðŸ“£ Binding data frames\nRemember, a vector is essentially a *column* of a single type of data. And data frames have to have columns with the same number of rows. So when binding rows, they need to be the same data `class` in each column, and when binding columns, they must have the same number of rows as the data frame. \n\n:::\n\n\n## Renaming\n\nOften times we need to rename our columns in order to make joining data easier, or for tables and plots that we want to share out. There are a few ways to rename columns in R.\n\nWe can use the `dplyr::rename()` function to specifically rename columns of interest. This requires the data, and a list of the columns we are interested in changing, formatted as: `new_name` = `old_name`.\n\n\n\n\n::: {.cell}\n```{webr}\n\n# rename with dplyr\ncscidat_lower <- rename(cscidat, \n              id = SampleID_old, \n              lat = New_Lat, \n              lon = New_Long)\nnames(cscidat_lower)\n```\n:::\n\n\n\n\nAnother great tool is the `{janitor}` package. We can use a number of functions in janitor, but most commonly I use it to clean all the column names. \n\n\n\n\n::: {.cell}\n```{webr}\n\n# rename all columns with janitor\ncscidat_janitor <- janitor::clean_names(cscidat)\nnames(cscidat_janitor)\n\n# take a look at options in the clean_names() function\n# how can we change the case to inital caps?\n# hint: help(\"clean_names\")\n\n```\n:::\n\n\n\n\n\n## Modifying and Summarizing Data\n\nWhen we want to add, revise, or summarize our data, we need to use a few additional functions in `{dplyr}`. We can use these to create new columns, calculate new data based on existing data, or create summaries based on different groups within our data.\n\n### `mutate` (adding columns)\n\nWeâ€™ve seen how to `filter` observations (rows) and `select` columns of a data frame. In `{dplyr}`, `mutate` allows us to add new columns to an existing data frame. These can be vectors you are adding or based on expressions applied to existing columns. For instance, maybe we want to convert a numeric column into a categorical using some criteria or maybe we want to make a new column based on some arithmetic on some other columns.\n\n\n\n\n::: {.cell}\n```{webr}\n\n# get observed taxa\nmut_1 <- mutate(cscidat, observed = OE * E)\n\nglimpse(mut_1)\n\n# add a column for lo/hi csci scores\nmut_2 <- mutate(mut_1, CSCIcat = ifelse(CSCI <= 0.79, 'lo', 'hi'))\nglimpse(mut_2)\n\n```\n:::\n\n\n\n\n\n### `bind` Data\n\nSometimes when we don't need to worry about joining specifically, and we want to append or mash datasets together, we can use the **bind** functions. There are base options as well as `{dplyr}` options. Let's revisit the `slice` function we used above, and make a new dataframe that is just the *StationCode*, *CSCI*, and *Lat* and *Lon* for the top 10 and bottom 10 CSCI values. We can bind rows, or bind columns, depending on what we are trying to do.\n\n\n\n\n::: {.cell}\n```{webr}\n# get top 10 highest CSCI scores \ncsci_top_10 <- slice_max(cscidat, order_by = CSCI, n = 10) |>   select(StationCode, CSCI, New_Lat, New_Long)\n\n# now get bottom 10\ncsci_bot_10 <- slice_min(cscidat, order_by=CSCI, n=10) |> \n    select(StationCode, CSCI, New_Lat, New_Long)\n\n# now BIND!\ncsci_top_bottom <- bind_rows(csci_top_10, csci_bot_10)\ncsci_top_bottom\n\n```\n:::\n\n\n\n\n## Joining\n\nCombining data is a common task of data wrangling. All joins require that each of the tables can be linked by shared identifiers. These are called â€˜keysâ€™ and are usually represented as a separate column that acts as a unique variable for the observations. Our example datasets include the id column that represents a unique identifier as a combination of station, sample date, and replicate.\n\nThe challenge with joins is that the two datasets may not represent the same observations for a given key. For example, you might have one table with all observations for every key, another with only some observations, or two tables with only a few shared keys. What you get back from a join will depend on whatâ€™s shared between tables, in addition to the type of join you use.\n\nFor our data, weâ€™ll be using an **`inner_join`** that combines datasets by shared keys (for an overview of the other types of joins, see [R4DS lesson here](https://r4ds.had.co.nz/relational-data.html#mutating-joins).\n\n![Figures by Garrick Adenbuie, see [here for more](https://www.garrickadenbuie.com/project/tidyexplain/)](https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/inner-join.gif)\n\n\n\n\n\n::: {.cell}\n```{webr}\nalldat <- inner_join(cscidat, ascidat, by = 'id')\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}